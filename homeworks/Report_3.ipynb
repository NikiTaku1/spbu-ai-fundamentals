{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff57a4de-9872-45ea-8335-fab9d1a9abe7",
   "metadata": {},
   "source": [
    "# Fake News Detection: изучениe эффективности методов\n",
    "\n",
    "## 1. Загрузка и анализ начальных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232cfb3a-a74f-4859-b244-7629acf49cf0",
   "metadata": {},
   "source": [
    "### Загрузка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc826a-24a7-4804-a803-6e087ce7b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae281fe-67b8-48e7-9723-a9f15d68fbb1",
   "metadata": {},
   "source": [
    "### Загрузка начальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8fe5b-de1f-4e93-9fb4-c8062dcfe718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('C:/Users/Zver/Desktop/uni/AIF/hw3/config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a626d1-fe3e-4b60-8461-3417ede2473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(cfg['fake_news']['train'])[['id', 'text', 'label']]\n",
    "test = pd.read_csv(cfg['fake_news']['test'])[['id', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e0063-652a-4360-a150-18e644c8aa0e",
   "metadata": {},
   "source": [
    "### Начальный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0968010-bf60-4bdb-8a6f-5e5439d6c6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train data shape: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc788f0-e57f-4822-a197-4d70233812f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Test data shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca750aab-b54f-4f67-9700-08450b8733d5",
   "metadata": {},
   "source": [
    "## Анализ и подготовка датасета\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f3072-9981-4c6d-8ed4-fc4d62230df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['label'].apply(lambda x: str(x).strip().isdigit())]\n",
    "train['label'] = train['label'].astype(int)\n",
    "print(f\"Train data shape after filtering: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d37e8c-31db-4144-8978-12e07603e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85f020-9eb9-49b3-ad40-0cb051cb7530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Text Preprocessing ===\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing TextPreprocessor...\")\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        print(\"TextPreprocessor initialized.\")\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        print(\"Cleaning text...\")\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "        cleaned_text = text.lower()\n",
    "        print(f\"Cleaned text sample: {cleaned_text[:100]}...\")\n",
    "        return cleaned_text\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        print(\"Tokenizing text...\")\n",
    "        tokens = word_tokenize(text)\n",
    "        print(f\"Number of tokens: {len(tokens)}\")\n",
    "        return tokens\n",
    "\n",
    "    def remove_stopwords(self, tokens):\n",
    "        print(\"Removing stopwords...\")\n",
    "        filtered_tokens = [token for token in tokens if token not in self.stop_words]\n",
    "        print(f\"Number of tokens after removing stopwords: {len(filtered_tokens)}\")\n",
    "        return filtered_tokens\n",
    "\n",
    "    def lemmatize(self, tokens):\n",
    "        print(\"Lemmatizing tokens...\")\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        print(f\"Lemmatized tokens sample: {lemmatized_tokens[:10]}...\")\n",
    "        return lemmatized_tokens\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        print(\"Preprocessing text...\")\n",
    "        text = self.clean_text(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        tokens = self.remove_stopwords(tokens)\n",
    "        tokens = self.lemmatize(tokens)\n",
    "        preprocessed_text = \" \".join(tokens)\n",
    "        print(f\"Preprocessed text sample: {preprocessed_text[:100]}...\")\n",
    "        return preprocessed_text\n",
    "\n",
    "text_preprocessor = TextPreprocessor()\n",
    "print(\"Applying TextPreprocessor to train data...\")\n",
    "train['text'] = train['text'].fillna(\"\").apply(text_preprocessor.preprocess_text)\n",
    "print(\"Applying TextPreprocessor to test data...\")\n",
    "test['text'] = test['text'].fillna(\"\").apply(text_preprocessor.preprocess_text)\n",
    "print(\"Text preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cd2d0-feab-4d2b-84d3-29b552717179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TF-IDF ===\n",
    "print(\"Starting TF-IDF Vectorization...\")\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2)) #Stop words removed in Text Preprocessor\n",
    "X = tfidf.fit_transform(train['text'])\n",
    "print(f\"Shape of TF-IDF matrix (X): {X.shape}\")\n",
    "X_test_final = tfidf.transform(test['text'])\n",
    "print(f\"Shape of TF-IDF matrix (X_test_final): {X_test_final.shape}\")\n",
    "y = train['label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4833e3-f418-4372-a4fa-20d0f04ebe45",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419799bf-8cae-4f14-9b09-19850d0815ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logistic Regression ===\n",
    "def objective_lr(trial):\n",
    "    print(\"Starting Logistic Regression Optuna trial...\")\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 10.0)\n",
    "    print(f\"Trial C value: {C}\")\n",
    "    model = LogisticRegression(C=C, max_iter=1000, solver='liblinear') #Added solver, prevents errors.\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "    print(f\"Trial score: {score}\")\n",
    "    print(\"Logistic Regression Optuna trial complete.\")\n",
    "    return score\n",
    "\n",
    "print(\"Starting Logistic Regression Optuna optimization...\")\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_lr.optimize(objective_lr, n_trials=3)\n",
    "print(\"Logistic Regression Optuna optimization complete.\")\n",
    "print(f\"Best Logistic Regression parameters: {study_lr.best_params}\")\n",
    "best_lr = LogisticRegression(C=study_lr.best_params['C'], max_iter=1000, solver='liblinear')\n",
    "best_lr.fit(X_train, y_train)\n",
    "val_lr = accuracy_score(y_val, best_lr.predict(X_val))\n",
    "print(f\"Logistic Regression Accuracy: {val_lr:.4f}\")\n",
    "\n",
    "# === LightGBM ===\n",
    "def objective_lgb(trial):\n",
    "    print(\"Starting LightGBM Optuna trial...\")\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.7, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.7, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True), #Added L1 Regularization\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True), #Added L2 Regularization\n",
    "\n",
    "    }\n",
    "    print(f\"Trial parameters: {params}\")\n",
    "    model = lgb.LGBMClassifier(**params, n_estimators=100, random_state=42) #Added random state\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "    print(f\"Trial score: {score}\")\n",
    "    print(\"LightGBM Optuna trial complete.\")\n",
    "    return score\n",
    "\n",
    "print(\"Starting LightGBM Optuna optimization...\")\n",
    "study_lgb = optuna.create_study(direction=\"maximize\")\n",
    "study_lgb.optimize(objective_lgb, n_trials=3)\n",
    "print(\"LightGBM Optuna optimization complete.\")\n",
    "print(f\"Best LightGBM parameters: {study_lgb.best_params}\")\n",
    "best_lgb = lgb.LGBMClassifier(**study_lgb.best_params, n_estimators=100, random_state=42)\n",
    "best_lgb.fit(X_train, y_train)\n",
    "val_lgb = accuracy_score(y_val, best_lgb.predict(X_val))\n",
    "print(f\"LightGBM Accuracy: {val_lgb:.4f}\")\n",
    "\n",
    "# === XGBoost ===\n",
    "def objective_xgb(trial):\n",
    "    print(\"Starting XGBoost Optuna trial...\")\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True), #Added gamma regularization\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True), # Added L1 reg\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 1.0, log=True), #Added L2 reg\n",
    "    }\n",
    "    print(f\"Trial parameters: {params}\")\n",
    "    model = XGBClassifier(**params, n_estimators=100, random_state=42) #Added random_state\n",
    "    score = cross_val_score(model, X_train, y_train, cv=3, scoring=\"accuracy\").mean()\n",
    "    print(f\"Trial score: {score}\")\n",
    "    print(\"XGBoost Optuna trial complete.\")\n",
    "    return score\n",
    "\n",
    "print(\"Starting XGBoost Optuna optimization...\")\n",
    "study_xgb = optuna.create_study(direction=\"maximize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=3)\n",
    "print(\"XGBoost Optuna optimization complete.\")\n",
    "print(f\"Best XGBoost parameters: {study_xgb.best_params}\")\n",
    "best_xgb = XGBClassifier(**study_xgb.best_params, n_estimators=100, use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "val_xgb = accuracy_score(y_val, best_xgb.predict(X_val))\n",
    "print(f\"XGBoost Accuracy: {val_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7296324-645e-483d-8dbb-96b64a68873c",
   "metadata": {},
   "source": [
    "### Анализ:\n",
    "\n",
    "Таким образом получены следующие оценки точности:\n",
    "\n",
    "Логистическая регрессия: 0.9747\n",
    "\n",
    "LightGBM: 0.9817\n",
    "\n",
    "XGBoost: 0.9805\n",
    "\n",
    "Ввиду особенностей работы библиотеки Optuna, данные значения ориентировочны и могут меняться даже при одинаковых параметрах обучения. В целом можно сделать вывод, что логистическая регрессия справляется хуже, чем LightGBM и XGBoost, которые показывают примерно одинаковый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee166f93-9575-4fad-b40c-9d90bb7fc51c",
   "metadata": {},
   "source": [
    "### Получение результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c021a-4ee3-47c8-9b8a-a62897b94970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Ensemble ===\n",
    "print(\"Starting Ensemble...\")\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', best_lr),\n",
    "        ('lgb', best_lgb),\n",
    "        ('xgb', best_xgb)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "ensemble.fit(X, y)\n",
    "print(\"Ensemble fitted.\")\n",
    "final_preds = ensemble.predict(X_test_final)\n",
    "print(\"Ensemble predictions made.\")\n",
    "\n",
    "submission = pd.DataFrame({'id': test['id'], 'label': final_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e85c6-5f74-4c9a-9788-46decde3c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7ded0-3914-41d1-91f1-b896638a1636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027a0ae-8da1-48b7-8526-8b53dddefa6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
